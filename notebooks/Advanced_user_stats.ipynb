{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../tasking_manager_stats/data_management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(get_data_dir(), 'merged_stats.csv'))\n",
    "df['date'] = df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-' + df['Day'].astype(str)\n",
    "df['date'] = pd.to_datetime(df['date'], yearfirst=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(df['Hour'] > 17) & (df['Hour'] < 22)]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapathons = pd.read_csv(os.path.join('..', 'data', 'Mapathons_2020_02_08.csv'))\n",
    "mapathons['Date'] = pd.to_datetime(mapathons['Date'], dayfirst=True)\n",
    "mapathons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapathons2 = pd.DataFrame()\n",
    "for _, row in mapathons.iterrows():\n",
    "    # Extract projects of the mapathon\n",
    "    tasks = row['Tasks']\n",
    "    if pd.isnull(tasks):\n",
    "        continue\n",
    "    projects = set()\n",
    "    for s in tasks.split('/'):\n",
    "        try:\n",
    "            projects.add(int(s))\n",
    "        except:\n",
    "            pass\n",
    "    for s in tasks.split(', '):\n",
    "        try:\n",
    "            projects.add(int(s))\n",
    "        except:\n",
    "            pass\n",
    "    # Create new mapathon line for each project\n",
    "    for project in projects:\n",
    "        mapathons2 = pd.concat([mapathons2, pd.DataFrame(data=[(row['Date'], row['City'], project)], columns=['date', 'City', 'Project'])], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapathons2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mapathons2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df2.loc[df2['Type'] == 'MAPPING'], mapathons2, on=['date', 'Project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3[['date', 'Author', 'City', 'Project']].drop_duplicates()\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df4[['Author', 'City']].drop_duplicates()\n",
    "tmp.loc[tmp['Author'] == 'NicolasGrosjean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[df4['Author'] == 'NicolasGrosjean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4[['Author', 'date']].drop_duplicates().groupby('Author').count().date.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.loc[df5['Author'] == 'NicolasGrosjean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mapathon_number(mapathon_file, stats_file, max_date=None):\n",
    "    mapathons = pd.read_csv(mapathon_file)\n",
    "    mapathons['Date'] = pd.to_datetime(mapathons['Date'], dayfirst=True)\n",
    "\n",
    "    # Extract projects of the mapathon\n",
    "    mapathons2 = pd.DataFrame()\n",
    "    for _, row in mapathons.iterrows():\n",
    "        tasks = row['Tasks']\n",
    "        if pd.isnull(tasks):\n",
    "            continue\n",
    "        projects = set()\n",
    "        for s in tasks.split('/'):\n",
    "            try:\n",
    "                projects.add(int(s))\n",
    "            except:\n",
    "                pass\n",
    "        for s in tasks.split(', '):\n",
    "            try:\n",
    "                projects.add(int(s))\n",
    "            except:\n",
    "                pass  \n",
    "        # Create new mapathon line for each project\n",
    "        for project in projects:\n",
    "            mapathons2 = pd.concat([mapathons2, pd.DataFrame(data=[(row['Date'], row['City'], project)], columns=['date', 'City', 'Project'])], axis=0, ignore_index=True)\n",
    "        \n",
    "    # Compute number of mapathons by contributor\n",
    "    df = pd.read_csv(stats_file)\n",
    "    df['date'] = df['Year'].astype(str) + '-' + df['Month'].astype(str) + '-' + df['Day'].astype(str)\n",
    "    df['date'] = pd.to_datetime(df['date'], yearfirst=True)\n",
    "    if max_date is not None:\n",
    "        df = df[df['date'] <= max_date]\n",
    "    df2 = df[(df['Hour'] > 17) & (df['Hour'] < 22)]\n",
    "    df3 = pd.merge(df2.loc[df2['Type'] == 'MAPPING'], mapathons2, on=['date', 'Project'])\n",
    "    df4 = df3[['date', 'Author', 'City', 'Project']].drop_duplicates()\n",
    "    return df4[['Author', 'date']].drop_duplicates().groupby('Author').count().date.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = compute_mapathon_number(os.path.join('..', 'data', 'Mapathons_2020_02_08.csv'),\n",
    "                              os.path.join(get_data_dir(), 'merged_stats.csv'))\n",
    "df6.loc[df6['Author'] == 'NicolasGrosjean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = datetime.datetime.strptime('2020-01-01', '%Y-%m-%d')\n",
    "df6 = compute_mapathon_number(os.path.join('..', 'data', 'Mapathons_2020_02_08.csv'),\n",
    "                              os.path.join(get_data_dir(), 'merged_stats.csv'), max_date)\n",
    "df6.loc[df6['Author'] == 'NicolasGrosjean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- WARNING : Divide validation time by simultanous validation tasks\n",
    "- Own mapping and validation time\n",
    "- Validation time on own mapping tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project = pd.read_csv(os.path.join(get_data_dir(), 'stats', '6055.csv'))\n",
    "df_project = df_project[df_project['Type'] == 'VALIDATION']\n",
    "df_project.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = ['Year', 'Month', 'Day', 'Rel. Day', 'Hour', 'Minute', 'Second', 'Duration', 'Author', 'Type']\n",
    "df_project2 = df_project.groupby(key).count().Task\n",
    "df_project2 = df_project2.reset_index()\n",
    "df_project2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project3 = pd.merge(df_project, df_project2, on=key)\n",
    "df_project3.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project3['Duration'] /= df_project3['Task_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project3['Duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_project['Duration'].sum() - 18*336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_validation_time_by_task(stats_dir, csv_file, max_date=None):\n",
    "    df_project = pd.read_csv(os.path.join(stats_dir, csv_file))\n",
    "    df_project = df_project[df_project['Type'] == 'VALIDATION']\n",
    "    if len(df_project) == 0:\n",
    "        return pd.DataFrame()\n",
    "    if max_date is not None:\n",
    "        df_project['date'] = df_project['Year'].astype(str) + '-' + df_project['Month'].astype(str) + '-' + df_project['Day'].astype(str)\n",
    "        df_project['date'] = pd.to_datetime(df_project['date'], yearfirst=True)\n",
    "        df_project = df_project[df_project['date'] <= max_date]\n",
    "        if len(df_project) == 0:\n",
    "            return pd.DataFrame()\n",
    "    key = ['Year', 'Month', 'Day', 'Rel. Day', 'Hour', 'Minute', 'Second', 'Duration', 'Author', 'Type']\n",
    "    df_project2 = df_project.groupby(key).count().Task\n",
    "    df_project2 = df_project2.reset_index()\n",
    "    df_project3 = pd.merge(df_project, df_project2, on=key)\n",
    "    df_project3['Duration'] /= df_project3['Task_y']\n",
    "    df_project3 = df_project3[['Project', 'Task_x', 'Duration']]\n",
    "    df_project3.columns = ['Project', 'Task', 'Duration']\n",
    "    df_project3 = df_project3.groupby(['Project', 'Task']).sum().reset_index()\n",
    "    return df_project3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_validation_time_by_task(os.path.join(get_data_dir(), 'stats'), '6055.csv')['Duration'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_validation_time_by_task_all_projects(stats_dir, max_date=None):\n",
    "    df = pd.DataFrame()\n",
    "    for file in tqdm(os.listdir(stats_dir)):\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.concat([df, compute_validation_time_by_task(stats_dir, file, max_date)], axis=0, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = compute_validation_time_by_task_all_projects(os.path.join(get_data_dir(), 'stats'))\n",
    "validation_df.columns = ['Project', 'Task', 'ValidationDuration']\n",
    "validation_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_author = pd.read_csv(os.path.join(get_data_dir(), 'merged_stats_one_author_by_task_type.csv'))\n",
    "df_one_author.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping = pd.merge(validation_df, df_one_author[df_one_author['Type'] == 'MAPPING'], on=['Project', 'Task'])\n",
    "df_mapping.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mapping[['Project', 'Task']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mapping_valid = df_mapping.groupby('Author').sum().ValidationDuration.reset_index()\n",
    "df_mapping_valid.sort_values('ValidationDuration', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pure_mapping = df[df['Type'] == 'MAPPING'].groupby('Author').sum().Duration.reset_index()\n",
    "df_pure_mapping.columns = ['Author', 'OwnMappingDuration']\n",
    "df_pure_mapping.sort_values('OwnMappingDuration', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pure_validation = df[df['Type'] == 'VALIDATION'].groupby('Author').sum().Duration.reset_index()\n",
    "df_pure_validation.columns = ['Author', 'OwnValidationDuration']\n",
    "df_pure_validation.sort_values('OwnValidationDuration', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advanced_stats(stats_dir, df_one_author, df, max_date=None):\n",
    "    validation_df = compute_validation_time_by_task_all_projects(stats_dir, max_date)\n",
    "    validation_df.columns = ['Project', 'Task', 'ValidationDuration']\n",
    "    df_mapping = pd.merge(validation_df, df_one_author[df_one_author['Type'] == 'MAPPING'], on=['Project', 'Task'])\n",
    "    df_mapping_valid = df_mapping.groupby('Author').sum().ValidationDuration.reset_index()\n",
    "    df_pure_mapping = df[df['Type'] == 'MAPPING'].groupby('Author').sum().Duration.reset_index()\n",
    "    df_pure_mapping.columns = ['Author', 'OwnMappingDuration']\n",
    "    res = pd.merge(df_pure_mapping, df_mapping_valid, on='Author', how='left')\n",
    "    df_pure_validation = df[df['Type'] == 'VALIDATION'].groupby('Author').sum().Duration.reset_index()\n",
    "    df_pure_validation.columns = ['Author', 'OwnValidationDuration']\n",
    "    res = pd.merge(res, df_pure_validation, on='Author', how='left')\n",
    "    res['ValidationOnOwnMappingDuration'] = res['ValidationDuration'] / res['OwnMappingDuration']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = compute_advanced_stats(os.path.join(get_data_dir(), 'stats'), df_one_author, df)\n",
    "df_adv.sort_values('ValidationOnOwnMappingDuration').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv[(~pd.isnull(df_adv['ValidationOnOwnMappingDuration'])) & (df_adv['OwnMappingDuration'] > 3600)].sort_values('ValidationOnOwnMappingDuration').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv[df_adv['ValidationDuration'] > 3600].sort_values('ValidationOnOwnMappingDuration').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = datetime.datetime.strptime('2020-01-01', '%Y-%m-%d')\n",
    "df_adv = compute_advanced_stats(os.path.join(get_data_dir(), 'stats'), df_one_author, df, max_date)\n",
    "df_adv[df_adv['ValidationDuration'] > 3600].sort_values('ValidationOnOwnMappingDuration').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
